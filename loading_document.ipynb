{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00d67c2-4263-4873-af3e-c2fab1deb1dc",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792a8b56-334d-4cfe-83c0-b9daa2add5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fad864-6640-4e3d-bc77-73541d2bc974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4528294-28be-4e2e-96ae-2b1196d73c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc02a50a-0fb7-4b94-b790-69c6f97612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ae1067-9a94-4587-bcda-0212ab13a8fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af4d551-f191-47c6-aea3-e9188bdf82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /opt/anaconda3/envs/myenv/lib/python3.13/site-packages (0.25.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install in the current Python environment\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pydub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ca053a-0fc5-4277-b0c5-4b033b14b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "whisper_model = whisper.load_model(\"base\")  # options: tiny, base, small, medium, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5083e3d2-205e-450a-b519-0d90c91775c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f1a690-9c69-446d-9913-6912453a952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9c6334-a512-41df-82ce-88a6827d92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7870709-491a-4445-90cf-60ad61c9d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d725ab43-4f1b-4ac9-9820-622880b2995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39b92f75-5eac-4028-b883-f47183e9a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the \n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb48707-60c4-4424-aa15-56b30d9fec83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb58263-69e4-40b2-9d58-b9511d082268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt_dlp in /opt/anaconda3/envs/myenv/lib/python3.13/site-packages (2025.9.26)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/envs/myenv/lib/python3.13/site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install yt_dlp\n",
    "! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5354d1a-3f43-4aea-aa37-ddecb51222cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /opt/anaconda3/envs/myenv/lib/python3.13/site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c7fdd7-bd91-49d7-8d2f-162efc386c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain_community.document_loaders.blob_loaders import FileSystemBlobLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fde5a4b4-5928-49aa-a486-9fc8f206526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295d5128-cfbd-49dd-90f7-fda95dd0c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# loader = GenericLoader(\n",
    "#     YoutubeAudioLoader([url],save_dir),  # fetch from youtube\n",
    "#     #FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),   #fetch locally\n",
    "#     OpenAIWhisperParser()\n",
    "# )\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f319fdae-81a4-4300-a504-356910f7c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download audio\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': os.path.join(save_dir, '%(title)s.%(ext)s'),\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "314528cf-e295-4e9e-a984-5fc9a74dec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading tv client config\n",
      "[youtube] jGwO_UgTS7I: Downloading tv player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading web safari player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 251\n",
      "[download] Sleeping 4.00 seconds as required by the site...\n",
      "[download] Destination: docs/youtube/Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).webm\n",
      "[download] 100% of   51.57MiB in 00:00:09 at 5.63MiB/s     \n",
      "[ExtractAudio] Destination: docs/youtube/Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).mp3\n",
      "Deleting original file docs/youtube/Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).webm (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading audio...\")\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c4148e-353e-4ce2-a3d6-f79fdd4b3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8875668-356c-49fd-9063-e06c607c38cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found audio files: ['Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a', 'Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).mp3']\n"
     ]
    }
   ],
   "source": [
    "# Find the downloaded audio file\n",
    "audio_files = [f for f in os.listdir(save_dir) if f.endswith(('.mp3', '.m4a', '.wav'))]\n",
    "print(f\"Found audio files: {audio_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eefacc-21e5-4b62-a788-318627cc4954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# Transcribe\n",
    "docs = []\n",
    "for audio_file in audio_files:\n",
    "    file_path = os.path.join(save_dir, audio_file)\n",
    "    print(f\"Transcribing {audio_file}...\")\n",
    "    result = whisper_model.transcribe(file_path)\n",
    "    docs.append(Document(\n",
    "        page_content=result[\"text\"],\n",
    "        metadata={\"source\": url, \"file\": audio_file}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de3da829-222f-4fca-9377-6c453922a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 2\n",
      " Welcome to CS229 Machine Learning. Some of you know that this class is for this Stanford for long time and this is often the class that I most look for to teaching each year because this is where we've helped I think several generations of Stanford students become experts in machine learning. Got built many of their products and services and startups that I'm sure many of you will pray all of you are using today. So what I want to do today was spend some time talking over logistics and then spe\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of docs: {len(docs)}\")\n",
    "if len(docs) > 0:\n",
    "    print(docs[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66439e7b-4218-46b9-9e73-0428759d88fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/Rnamrata/image_enhancement_for_social_robots/blob/master/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b941ac5f-abef-49bf-8ef6-eedca60de9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6914deae-b0e5-441f-b39a-022aa3e57b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of docs: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8c53ec2-64b4-43e6-bbd3-fe3aab66d597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "image_enhancement_for_social_robots/README.md at master · Rnamrata/image_enhancement_for_social_robots · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Navigation Menu\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign in\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Appearance settings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Platform\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Copilot\n",
      "\n",
      "        \n",
      "\n",
      "        Write better code wit\n"
     ]
    }
   ],
   "source": [
    "if len(docs) > 0:\n",
    "    print(docs[0].page_content[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31246eb-9c09-4f92-baa3-2cefb081277f",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de28b6-6e4d-42f0-92d1-6509b4bca702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f56cca5-d893-44db-977c-8475862734bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae6cb66f-eb09-437c-b79d-f13b2ebea1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec0caad8-fbf3-43ea-a5e0-8a7abc2d2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5e38455-a698-4bba-b154-b66092381ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4cf1efe-ec13-4550-ba86-03d9c4ae6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1f2db9f-03de-4885-990b-03d21344100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e702a7d-6a55-4d0e-a543-782f17d8de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ac2d447-8de7-48ab-a544-ef40754658f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3978d92f-90c3-4147-afaf-7ba1ba32102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f639418-fdcf-4485-a26f-9872428c1250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6913b-3da4-45b4-9370-23d7a1d3fe7d",
   "metadata": {},
   "source": [
    "### Recursive Splitting Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cd42e6c-8f04-4288-ba50-f8e32c5f1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f5b013a-4c83-4adb-9015-1d4a824e8db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a12a40cf-bd1c-48cb-80a4-c7980f2a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7683a9ff-1bd0-42ef-8c73-2bb451229cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf31e5f3-2442-4e49-83a4-8abb1896edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "106fca7f-2515-4179-8bd0-8cd268aa1c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/nb/77hjsc2j58s68phj_xx_yps80000gn/T/ipykernel_33422/158012430.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24d955c0-8837-4fef-bc29-310e6d92fe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/nb/77hjsc2j58s68phj_xx_yps80000gn/T/ipykernel_33422/2945222903.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "094e015b-544c-4b88-ab30-6b7f07f5c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "407d6d5d-6aac-4ea8-9856-d96197e9ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06217b9d-3948-4749-8521-9cbec74047be",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7baa783b-ae4e-469b-aa5f-9f0036218754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "342187e5-e874-4cde-9729-e5fc6c216c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff399e2e-b5c7-4eb6-ab5c-e79ab5d827b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}, page_content='MachineLearning-Lecture01  \\n')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fd399fbf-fca8-4b3c-94f8-0f64035c36fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}, page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we\\'ll start to talk a bit about machine learning.  \\nBy way of introduction, my name\\'s Andrew Ng and I\\'ll be instructor for this class. And so \\nI personally work in machine learning, and I\\'ve worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I\\'m actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learning and all aspects of machine learning. Paul Baumstarck \\nworks in machine learning and computer vision. Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computational biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much better throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find learning algorithms to problems \\nin computer vision and biology and robots and language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in computer systems or databases to economists \\nand sort of also an unending stream of people from industry coming to Stanford \\ninterested in applying machine learning methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \\nin \"Computer World\" about the 12 IT skills that employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirable skills in all of IT and all of information technology, and \\ntopping the list was actually machine learning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learning algorithms is one of the things that \\ntouches many areas of science and industries, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from EE? Oh, okay, maybe about a fifth. How')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603f860-cfcf-49c9-8092-12d15fe177ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db5f3538-fce4-4a2a-8eb0-0ee506df5585",
   "metadata": {},
   "source": [
    "### Token Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "81831e2f-8caa-456b-b914-02669945e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "01f9c3b3-e542-4828-a7a3-befb9f449a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22309489-c982-4e49-91b8-e837ca22b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ff2e1c7b-323e-4e37-bb4a-e0b8daef1e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "80d57320-7919-41f1-9012-3995402f4a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning class. So what I wanna do today is'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ce869e9-8cc7-46d8-9484-8aaed6500390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eace66e-61ba-41d7-b5c3-d1320310d1cb",
   "metadata": {},
   "source": [
    "### Context Aware Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "92055bea-50e7-43be-b0f8-e6349bb9f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6aeb1512-4026-4c90-8957-ad7f5d2005c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d03f8824-4c58-4a3a-8970-4338ee356efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11e4b9fb-b058-4a4c-b15f-ec3f894cad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a8c0d400-b746-4ac2-b463-620bbec6be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c93ca508-c53a-4f40-b6ca-a3f8e2a23ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "23133b72-96f0-4056-b3e7-52d023c12d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "364877fa-20ab-49a7-a1fa-e1031f381f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d8aef0cb-a928-4e80-923e-d21b54e5f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "md_header_splits = markdown_splitter.split_text(txt)\n",
    "splits = text_splitter.split_documents(md_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2d5d3a8b-3bd2-4f67-bfd9-6bd4259d3180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7afcc180-fb0b-4b9b-87fe-fbe585b5a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"MachineLearning-Lecture01\\nInstructor (Andrew Ng): Okay. Good morning . Welcome to CS229, the machine\\nlearning class. So what I wanna do today is  just spend a little time going over the logistics\\nof the class, and then we'll start  to talk a bit about machine learning.\\nBy way of introduction, my name's Andrew  Ng and I'll be instructor for this class.  And so\\nI personally work in machine learning , and I've worked on it for about 15  years now, and\\nI actually think that  machine learning is the most exciting field of all the  computer\\nsciences. So I'm actually  always excited about teaching this class. Sometimes I actually\\nthink that machine learning is not only the  most exciting thing in computer science, but\\nthe most exciting thing in all of human endeavor,  so maybe a little bias there.\\nI also want to introduce the TAs, who  are all graduate students doing research in or\\nrelated to the machine learning and all aspects of machine  learning. Paul Baumstarck\")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "41d3284e-3c74-40fd-bb61-46f0976bb9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning-Lecture01\\nInstructor (Andrew Ng): Okay. Good morning . Welcome to CS229, the machine\\nlearning class. So what I wanna do today is  just spend a little time going over the logistics\\nof the class, and then we'll start  to talk a bit about machine learning.\\nBy way of introduction, my name's Andrew  Ng and I'll be instructor for this class.  And so\\nI personally work in machine learning , and I've worked on it for about 15  years now, and\\nI actually think that  machine learning is the most exciting field of all the  computer\\nsciences. So I'm actually  always excited about teaching this class. Sometimes I actually\\nthink that machine learning is not only the  most exciting thing in computer science, but\\nthe most exciting thing in all of human endeavor,  so maybe a little bias there.\\nI also want to introduce the TAs, who  are all graduate students doing research in or\\nrelated to the machine learning and all aspects of machine  learning. Paul Baumstarck\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "47be6c6b-a2c1-46f4-a215-418a60886fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"related to the machine learning and all aspects of machine  learning. Paul Baumstarck\\nworks  in machine learning and computer vision. Catie Chang  is actually a neuroscientist\\nwho applies  machine learning algorithms to try to understand the human brain . Tom Do\\nis another PhD student,  works in computational biology and in sort of the basic\\nfundamentals of human learning. Z ico Kolter is the head TA — he's  head TA two years\\nin a row now  — works in machine learning a nd applies them  to a bunch of robots. And\\nDaniel  Ramage is — I guess he's not here   — Daniel applies l earning algorithms to\\nproblems in natural language processing.\\nSo you'll get to know the TAs and  me much better throughout this quarter, but just from\\nthe sorts of things the TA's do , I hope you can already tell that machine learning  is a\\nhighly interdisciplinary topic in which  just the TAs find learning algorithms to problems\""
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0a1bfe0c-ca9e-4c28-add8-3fcafde25cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e6b9c7f-1f9f-42ad-ba69-3b382aba1967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "629c0e91-8107-448b-b488-a609ca8deb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='MachineLearning-Lecture01\\nInstructor (Andrew Ng): Okay. Good morning . Welcome to CS229, the machine\\nlearning class. So what I wanna do today is  just spend a little time going over the logistics\\nof the class, and then we\\'ll start  to talk a bit about machine learning.\\nBy way of introduction, my name\\'s Andrew  Ng and I\\'ll be instructor for this class.  And so\\nI personally work in machine learning , and I\\'ve worked on it for about 15  years now, and\\nI actually think that  machine learning is the most exciting field of all the  computer\\nsciences. So I\\'m actually  always excited about teaching this class. Sometimes I actually\\nthink that machine learning is not only the  most exciting thing in computer science, but\\nthe most exciting thing in all of human endeavor,  so maybe a little bias there.\\nI also want to introduce the TAs, who  are all graduate students doing research in or\\nrelated to the machine learning and all aspects of machine  learning. Paul Baumstarck\\nworks  in machine learning and computer vision. Catie Chang  is actually a neuroscientist\\nwho applies  machine learning algorithms to try to understand the human brain . Tom Do\\nis another PhD student,  works in computational biology and in sort of the basic\\nfundamentals of human learning. Z ico Kolter is the head TA — he\\'s  head TA two years\\nin a row now  — works in machine learning a nd applies them  to a bunch of robots. And\\nDaniel  Ramage is — I guess he\\'s not here   — Daniel applies l earning algorithms to\\nproblems in natural language processing.\\nSo you\\'ll get to know the TAs and  me much better throughout this quarter, but just from\\nthe sorts of things the TA\\'s do , I hope you can already tell that machine learning  is a\\nhighly interdisciplinary topic in which  just the TAs find learning algorithms to problems\\nin computer vision and biology and robots and language . And machine learning is one of\\nthose  things that has and is having a large impact on  many applications.\\nSo just in my  own daily work, I actually frequently end up talking  to people like\\nhelicopter pilots to  biologists to people in computer systems or databases to economists\\nand sort of also an unending stream  of people from industry coming to Stanford\\ninterested  in applying machine learning methods to their own problems.\\nSo yeah, this is fun.  A couple of weeks ago, a student actually forwarded  to me an article\\nin \"Computer World \" about the 12 IT skills that employers can\\'t  say no to. So it\\'s about\\nsort of the 12 most desirable skills in all of  IT and all of information technology, and\\ntopping the list was actually machine learning. So  I think this is a good time to be\\nlearning this stuff and learning algorithms and having a  large impact on many segments\\nof science and  industry.\\nI\\'m actually curious about  something. Learning algorithms is one of the things that\\ntouches many areas of science and  industries, and I\\'m just kind of curious.  How many\\npeople here are computer science majors , are in the computer science department? Okay.\\nAbout half of you. How many people  are from EE? Oh, okay, maybe about  a fifth. How many biologers are there here? Wow,  just a few, not many. I\\'m surprised . Anyone from\\nstatistics? Okay,  a few. So where are the rest of you  from?\\nStudent : iCME .\\nInstructor (Andrew Ng)  : Say again?\\nStudent : i CME.\\nInstructor (Andrew  Ng) : iCME. Cool.\\nStudent : [Inaudible].\\nInstructor (Andrew Ng) : Civ i and what else?\\nStudent :  [Inaudible]\\nInstructor  (Andrew Ng) : Synthesis, [ina udible] systems. Yeah, cool.\\nStudent : Chemi.\\nInstructor (Andrew Ng) : Chemi.  Cool.\\nStudent : [Inaud ible].\\nInstructor (Andrew Ng ) : Aero/astro. Yes, right . Yeah, okay, cool. Anyone else?\\nStudent : [Inaudible].\\nInstructor (Andrew Ng) :  Pardon? MSNE. All right. Cool . Yeah.\\nStudent : [In audible].\\nInstructor (Andrew  Ng) : Pardon?\\nStudent  : [Inaudible].\\nInstruct or (Andrew Ng) : Endo —\\nStudent : [Inaudible].\\nInstructor (Andrew Ng) : Oh , I see, industry. Okay. Cool.  Great, great. So as you can\\ntell from a cross-section of this class,  I think we\\'re a very diverse audience in this  room,\\nand that\\'s one of the  things that makes this class fun to teach and fun  to be in, I think. So in this class, we\\'ve tried to convey  to you a broad set of principles and tools that  will\\nbe useful for doing many, many  things. And every time I teach this class,  I can actually\\nvery confidently say that after  December, no matter what you\\'re going to do  after this\\nDecember when you\\'ve sort of  completed this class, you\\'ll find the things you  learn in\\nthis class very useful, and  these things will be useful pretty much no matter what  you end\\nup doing later in your life .\\nSo I have more logistics to  go over later, but let\\'s say a few  more words about machine\\nlearning. I feel  that machine learning grew out of early work in AI , early work in artificial\\nintelligence. And  over the last — I wanna say last 15 or  last 20 years or so, it\\'s been\\nviewed as a sort of growing new capability  for computers. And in particular, it turns out\\nthat there are many programs or there are  many applications that you can\\'t program by\\nhand.\\nFor example, if you  want to get a computer to read handwritten characters,  to read sort of\\nhandwritten digits,  that actually turns out to be amazingly difficult to write  a piece of\\nsoftware to take this input , an image of something that I wrote and to  figure out just what\\nit is, to  translate my cursive handwriting into — to extract the  characters I wrote out in\\nlonghand . And other things: One thing that my students  and I do is autonomous flight. It\\nturns out to be extremely difficult to sit down  and write a program to fly a helicopter.\\nBut in contrast, if you want to  do things like to get software to fly a helicopter  or have\\nsoftware recognize handwritten digits, one  very successful approach is to use a learning\\nalgorithm and have a computer learn by itself how  to, say, recognize your handwriting.\\nAnd in fact, handwritten digit recognition, this is  pretty much the only approach that\\nworks well . It uses applications that are hard to program by  hand.\\nLearning algorithms has also made  I guess significant inroads in what\\'s sometimes called\\ndatabase mining. So, for example,  with the growth of IT and computers, increasingly\\nmany hospitals are keeping around medical records of what  sort of patients, what\\nproblems they  had, what their prognoses was, what  the outcome was. And taking all of\\nthese medical records, which started to be digitized  only about maybe 15 years, applying\\nlearning  algorithms to them can turn raw medical records into what  I might loosely call\\nmedical knowledge in which  we start to detect trends in medical practice and even  start to\\nalter medical practice as a result  of medical knowledge that\\'s derived by applying\\nlearning algorithms to the sorts of medical records that hospitals  have just been building\\nover the last 15 , 20 years in an electronic format.\\nTurns out that most of you probably use  learning algorithms — I don\\'t know — I think\\nhalf a dozen times a day or maybe  a dozen times a day or more, and often  without\\nknowing it. So, for  example, every time you send mail via the US  Postal System, turns\\nout there\\'s an  algorithm that tries to automatically read the zip code you  wrote on your\\nenvelope, and  that\\'s done by a learning algorithm. So every  time you send US mail, you\\nare  using a learning algorithm, perhaps without even being aware  of it. Similarly, every time you write a check, I  actually don\\'t know the number for this, but  a\\nsignificant fraction of checks that you write  are processed by a learning algorithm that\\'s\\nlearned to read the digits, so the dollar  amount that you wrote down on your check. So\\nevery time you write a check, there \\'s another learning algorithm that you\\'re probably\\nusing without even being aware of it.\\nIf you use a credit card, or I  know at least one phone company was doing this,  and lots of\\ncompanies like eBay as  well that do electronic transactions, there\\'s a good  chance that\\nthere\\'s a learning algorithm in  the background trying to figure out if, say,  your credit\\ncard\\'s been stolen or if  someone\\'s engaging in a fraudulent transaction.\\nIf you use a website like Amazon or Netflix  that will often recommend books for you to\\nbuy or movies for you to rent or whatever,  these are other examples of learning\\nalgorith ms that have learned what sorts of things you like  to buy or what sorts of movies\\nyou  like to watch and can therefore give customized recommendations to  you.\\nJust about a week ago , I had my car serviced, and even  there, my car mechanic was trying\\nto  explain to me some learning algorithm in the innards  of my car that\\'s sort of doing its\\nbest to optimize my driving performance for fuel efficiency  or something.\\nSo, see,  most of us use learning algorithms half a dozen,  a dozen, maybe dozens of times\\nwithout  even knowing it.\\nAnd of course , learning algorithms are also doing things like giving us  a growing\\nunderstanding of the human genome . So if someday we ever find a cure for  cancer, I bet\\nlearning algorithms will have  had a large role in that. That\\'s sort  of the thing that Tom\\nworks on,  yes?\\nSo in teaching this class , I sort of have three goals. One of  them is just to I hope convey\\nsome  of my own excitement about machine learning to you.\\nThe second goal is by the end  of this class, I hope all of you will  be able to apply state-of-\\nthe -art machine learning algorithms to whatever problems you\\'re  interested in. And if you\\never need  to build a system for reading zip codes, you \\'ll know how to do that by the end\\nof this class.\\nAnd last ly, by the end of this class, I  realize that only a subset of you are interested in\\ndoing research in machine learning, but by  the conclusion of this class, I hope that all  of\\nyou will actually be well qualified to  start doing research in machine learning, okay?\\nSo let\\'s say a few words about  logistics. The prerequisites of this class are written  on one\\nof the handouts, are  as follows: In this class, I\\'m going  to assume that all of you have sort\\nof basic knowledge of computer science and knowledge of the  basic computer skills and\\nprinciples.  So I assume all of you know what big? O notation, that all of you know about\\nsort of data structures like queues, stacks,  binary trees, and that all of you know enough\\nprogramming skills to, like, write  a simple computer program. And it turns out that  most of this class will not be very programming intensive,  although we will do some\\nprogramming,  mostly in either MATLAB or Octave. I \\'ll say a bit more about that later.\\nI also assume familiarity with basic probability and  statistics. So most undergraduate\\nstatistics class , like Stat 116 taught here at Stanford, will  be more than enough. I\\'m gonna\\nassume all of you know what random variables are , that all of you know what expectation\\nis, what a variance or a random variable is . And in case of some of you, it \\'s been a while\\nsince you\\'ve seen  some of this material. At some of the discussion  sections, we\\'ll actually\\ngo over some  of the prerequisites, sort of as a refres her course under prerequisite class.\\nI\\'ll  say a bit more about that later as well.\\nLastly, I also assume familiarity with  basic linear algebra. And again, most undergraduate\\nlinear algebra courses are more than enough. So  if you\\'ve taken courses like Math 51,\\n103, Math 113 or CS205 at Stanford , that would be more than enough. Basically,  I\\'m\\ngonna assume that all of  you know what matrixes and vectors are, that  you know how to\\nmultiply mat rices and vectors and multiply matrix and matrices,  that you know what a\\nmatrix inverse  is. If you know what an eigenvector  of a matrix is, that\\'d be even better .\\nBut if you don\\'t quite know  or if you\\'re not quite sure, that\\'s  fine, too. We\\'ll go over it in\\nthe review sections.\\nSo  there are a couple more logistical things I should deal  with in this class. One is that, as\\nmost of you know, CS229 is  a televised class. And in fact, I guess  many of you are\\nprobably watching this at  home on TV, so I\\'m gonna say hi  to our home viewers.\\nSo earlier  this year, I approached SCPD, which telev ises these classes, about trying to\\nmake  a small number of Stanford classes publicly available or posting  the videos on the\\nweb. And so  this year, Stanford is actually starting a small pilot  program in which we\\'ll\\npost videos of  a small number of classes online, so on the  Internet in a way that makes it\\npublic ly accessible to everyone. I\\'m very excited about  that because machine learning in\\nschool, let \\'s get the word out there.\\nOne of the consequences of this is that — let \\'s see — so videos  or pictures of the  students\\nin this classroom will not be posted  online, so your images — so don\\'t worry  about being\\nby seeing your own face appear  on YouTube one day. But the microphones may pick  up\\nyour voices, so I guess the  consequence of that is that because microphones may pick up\\nyour voices, no matter how irritated you  are at me, don\\'t yell out swear words  in the\\nmiddle of class, but because  there won\\'t be video you can safely sit there  and make faces\\nat me, and that  won\\'t show, okay?\\nLet \\'s see. I also handed out this — ther  e were two handouts I hope most of you  have,\\ncourse information handout. So  let me just say a few words about parts of  these. On the\\nthird page, there \\'s a section that says Online Resources.\\nOh, okay. Louder? Actually,  could you turn up the volume? Testing. Is  this better?\\nTesting, testing. Okay , cool. Thanks. So all right, online resources. The class has  a home page, so it\\'s in on the  handouts. I\\nwon\\'t write on  the chalkboard — http:// cs229.stan ford.edu. And so when there are\\nhomework assignments or things like that, we  usually won\\'t sort of — in the mission of\\nsaving trees, we will usually not give  out many handouts in class. So homework\\nassignments, homework solutions will be posted  online at the course home page.\\nAs far as this class, I\\'ve also written , and I guess I\\'ve also revised every year  a set of\\nfairly detailed lecture notes  that cover the technical content of this class. And  so if you\\nvisit the course homepage , you\\'ll also find the detailed lecture notes that  go over in detail\\nall the math and  equations and so on that I\\'ll be doing in  class.\\nThere\\'s also a news group, su.class.cs229, also  written on the handout. This is a\\nnewsgroup that\\'s sort of a forum for  people in the class to get to know each other  and\\nhave whatever discussions you want to have  amongst yourselves. So the class newsgroup\\nwill not be monitored by the TAs and me . But this is a place for you to form  study groups\\nor find project partners or discuss  homework problems and so on, and it\\'s not  monitored\\nby the TAs and me.  So feel free to talk trash about this class there .\\nIf you want to contact the  teaching staff, please use the email address written down  here,\\ncs229-qa@cs .stanford.edu. This goes to an  account that\\'s read by all the TAs and  me. So\\nrather than sending us email  individually, if you send email to this account,  it will\\nactually let us get back to  you maximally quickly with answers to your questions.\\nIf you\\'re asking questions about homework  problems, please say in the subject line which\\nassignment and which question the email refers to , since that will also help us to route\\nyour question to the appropriate TA or to me  appropriately and get the response back to\\nyou  quickly.\\nLet\\'s see. Sk ipping ahead — let\\'s see — for homework,  one midterm, one open and term\\nproject . Notice on the honor code. So one thing  that I think will help you to succeed and\\ndo well in this class and even help you  to enjoy this class more is if you form a  study\\ngroup.\\nSo start  looking around where you\\'re sitting now or at the  end of class today, mingle a\\nlittle bit and get to know your classmates. I  strongly encourage you to form study groups\\nand  sort of have a group of people to study with  and have a group of your fellow students\\nto talk over these concepts with. You can also  post on the class newsgroup if you want to\\nuse that to try to form a study  group.\\nBut some of the problems  sets in this class are reasonably difficult. People that  have\\ntaken the class before may tell  you they were very difficult. And just I bet  it would be\\nmore fun for you,  and you\\'d probably have a better learning experience if  you form a\\nstudy group of people to  work with. So I definitely encourage you to do  that.\\nAnd just to say a  word on the honor code, which is I definitely  encourage you to form a\\nstudy group and  work together, discuss homework problems together. But if  you discuss homework problems with other students, then I\\'ll  ask you to sort of go home and write\\ndown your own solutions independently without referring to notes  that were taken in any\\nof your joint  study sessions.\\nSo in other words , when you turn in a homework problem, what  you turn in should be\\nsomething that was  reconstructed independently by yourself and without referring to\\nnotes that you took during your study sessions with other  people, okay? And obviously,\\nsh owing your solutions to others or copying other solutions directly  is right out.\\nWe occasionally also  reuse problem set questions from previous years so that the\\nproblems are a bit more debugged  and work more smoothly. And as a result of  that, I also\\nask you not to  look at solutions from previous years, and this includes  both sort of official\\nsolutions that we \\'ve given out to previous generations of this class and  previous solutions\\nthat people that have taken this  class in previous years may have written out by\\nthemselves, okay?\\nSadly , in this class, there are usually — sadly , in previous y ears, there have often been  a\\nfew honor code violations in this class . And last year, I think I prosecuted five  honor code\\nviolations, which I think  is a ridiculously large number. And so just don \\'t work without\\nsolutions, and hopefully  there\\'ll be zero honor code violations this year.  I\\'d love for that\\nto happen.\\nThe section here on the late homework  policy if you ever want to hand in a homework\\nlate, I\\'ll leave you to read  that yourself.\\nWe also have a  midterm, which is scheduled for Thursday, 8th  of November at 6:00 p.m.,\\nso please keep that evening free.\\nAnd let\\'s see. And one more  administrative thing I wanted to say is about the class\\nproject. So part of the goal of  this class is to leave you well equipped to apply  machine\\nlearning algorithms to a problem or to  do research in machine learning. And so as part  of\\nthis class, I\\'ll ask you  to execute a small research project sort of as a  small term project.\\nAnd what most  students do for this is either apply machine learning to  a problem that you\\nfind interesting or investigate  some aspect of machine learning. So to those of  you that\\nare either already doing research or  to those of you who are in industry, you \\'re taking this\\nfrom a company, one  fantastic sort of way to do a class project would  be if you apply\\nmachine learning algorithms to  a problem that you\\'re interested in, to a  problem that\\nyou\\'re already working on,  whether it be a science research problem or sort of  a problem\\nin industry where you\\'re trying  to get a system to work using a learning algorithm .\\nTo those of you that are  not currently doing research, one great way to do  a project would\\nbe if you apply learning  algorithms to just pick a problem that you care about . Pick a\\nproblem that you find interesting , and apply learning algorithms to that and play with  the\\nideas and see what happens. And let\\'s see. Oh, and the goal  of the project should really be for you to do  a publishable\\npiece of research in machine  learning, okay?\\nAnd if you  go to the course website, you\\'ll actually find  a list of the projects that students\\nhad  done last year. And so I\\'m holding the  list in my hand. You can go home later  and\\ntake a look at it online.\\nBut reading down this list, I  see that last year, there were students that applied  learning\\nalgorithms to control a snake  robot. There was a few projects on improving learning\\nalgorithms. There\\'s a project  on flying autonomous aircraft. There was a project actually\\ndone by our TA Paul on improving computer  vision algorithms using machine learning.\\nThere  are a couple of projects on Netflix rankings using learning  algorithms; a few\\nmedical robots; ones  on segmenting [inaudible] to segment ing pieces of the body using\\nlearning algorithms ; one on musical instrument detection; another on irony  sequence\\nalignment; and a few algorithms  on understanding the brain neuroscience, actually quite a\\nfew projects on neuroscience; a couple of projects  on undescending fMRI data on brain\\nscans, and so on; another project  on market makings, the financial trading. There  was an\\ninteresting project on trying to use  learning algorithms to decide what is it that makes a\\nperson\\'s face physically attractive. There\\'s  a learning algorithm on optical illusions, and\\nso on.\\nAnd it goes on , so lots of fun projects. And take a  look, then come up with your own\\nideas. But whatever you find cool and interesting , I hope you\\'ll be able to make machine\\nlearning a project out of it. Yeah , question?\\nStudent : Are these  group projects?\\nInstructor (Andrew  Ng): Oh, yes, thank you.\\nStudent : So how many people can be  in a group?\\nInstructor ( Andrew Ng): Right. So projects can be done  in groups of up to three people.\\nSo as part of forming study groups, later today  as you get to know your classmates, I\\ndefinitely also encourage you to grab two other  people and form a group of up to three\\npeople for your project, okay? And just  start brainstorming ideas for now amongst\\nyour selves. You can also come and talk to me  or the TAs if you want to brainstorm ideas\\nwith us.\\nOkay.  So one more organizational question. I\\'m curious,  how many of you know\\nMATLAB?  Wow, cool, quite a lot. Okay.  So as part of the — act ually how  many of you\\nknow Octave or have  used Octave? Oh, okay, much smaller  number.\\nSo as part of this  class, especially in the homeworks, we\\'ll  ask you to implement a few\\nprograms , a few machine learning algorithms as part of the  homeworks. And most of those homeworks will be done in either MATLAB  or in Octave, which is sort of —  I\\nknow some people call it a free  version of MATLAB, which it sort of is , sort of isn\\'t.\\nSo  I guess for those of you that haven\\'t seen  MATLAB before, and I know most of you\\nhave, MATLAB is I guess part  of the programming language that makes it very easy to\\nwrite codes using matrices, to write  code for numerical routines, to move data around,  to\\nplot data. And it\\'s sort  of an extremely easy to learn tool to use for  implementing a lot of\\nlearning algorithms.\\nAnd in case some of you want to  work on your own home computer or something if you\\ndon\\'t have a MATLAB license,  for the purposes of this class, there\\'s also  — [inaudible]\\nwrite that  down [inaudible] MATLAB — there \\' s also a software package called Octave\\nthat you can download for free off the Internet . And it has somewhat fewer features than\\nMATLAB, but it\\'s free, and for  the purposes of this class, it will work for  just about\\neverything.\\nSo  actually I, well, so yeah, just a  side comment for those of you that haven\\'t seen\\nMATLAB before I guess, once a  colleague of mine at a different university, not at\\nStanford, actually teaches another machine learning  course. He\\'s taught it for many years.\\nSo one day, he was in his  office, and an old student of his from,  like, ten years ago came\\ninto his  office and he said, \"Oh, professor,  professor, thank you so much for your\\nmachine learning class. I learned so much from it . There\\'s this stuff that I learned in your\\nclass, and I now use every day . And it\\'s helped me make lots of money , and here\\'s a\\npicture of my  big house.\"\\nSo my friend was  very excited. He said, \"Wow. That \\'s great. I\\'m glad to hear this\\nmachine learning stuff was actually useful. So what  was it that you learned? Was it\\nlogistic regression? Was it the PCA?  Was it the data networks? What was it that  you\\nlearned that was so helpful?\"  And the student said, \"Oh, it was  the MATLAB.\"\\nSo for those  of you that don\\'t know MATLAB yet,  I hope you do learn it. It\\'s not  hard,\\nand we\\'ll actually have a  short MATLAB tutorial in one of the discussion sections  for\\nthose of you that don\\'t know  it.\\nOkay. The very last  piece of logistical thing is the discussion sections. So  discussion\\nsections will be taught by the T As, and attendance at discussion sections is optional,\\nalthough they\\'ll also be recorded and televised . And we\\'ll use the discussion sections\\nmainly for two things. For the next two  or three weeks, we\\'ll use the discussion sections\\nto go over the prerequisites to this  class or if some of you haven\\'t seen probability  or\\nstatistics for a while or maybe  algebra, we\\'ll go over those in the discussion  sections as a\\nrefresher for those  of you that want one.\\nLater  in this quarter, we\\'ll also use the discussion  sections to go over extensions for the\\nmaterial  that I\\'m teaching in the main lectures. So  machine learning is a huge field, and\\nthere are a few extensions that we really want to  teach but didn\\'t have time in the main\\nlectures for. So later this quarter, we\\'ll use the discussion  sections to talk about things like convex\\noptimization, to talk a little bit about hidden  Markov models, which is a type of machine\\nlearning algorithm for modeling time series and a  few other things, so extensions to the\\nmaterials that I\\'ll be covering in the main  lectures. And attendance at the discussion\\nsections  is optional, okay?\\nSo that  was all I had from logistics. Before we move  on to start talking a bit about\\nmachine  learning, let me check what questions you have.  Yeah?\\nStudent : [Inaud ible] R or something like that?\\nInstructor (Andrew Ng) : Oh,  yeah, let\\'s see, right. So our  policy has been that you\\'re\\nwelcome  to use R, but I would strongly advise against  it, mainly because in the last\\nproblem  set, we actually supply some code that will run  in Octave but that would be\\ns omewhat painful for you to translate into R yourself . So for your other assignments, if\\nyou wanna submit a solution in R, that\\'s  fine. But I think MATLAB is actually totally\\nworth learning. I know R and MAT LAB, and I personally end up using MATLAB  quite a\\nbit more often for various reasons . Yeah?\\nStudent : For the  [inaudible] project [inaudible ]?\\nInstructor (Andrew Ng ) : So for the term project, you\\'re  welcome to do it in smaller\\ngroups of  three, or you\\'re welcome to do it by  yourself or in groups of two. Grading is  the\\nsame regardless of the group size,  so with a larger group, you probably — I  recommend\\ntrying to form a team,  but it\\'s actually totally fine to do it in  a smaller group if you want.\\nStudent : [Inaudible] what language [ inaudible]?\\nInstructor  (Andrew Ng): So let\\'s see. There  is no C programming in this class other\\nthan any that you may choose to do yourself in  your project. So all the homeworks can be\\ndone in MATLAB or Octave,  and let\\'s see. And I guess the program  prerequisites is more\\nthe ability to understand  big?O notation and knowledge of what a data  structure, like a\\nlinked list or a  queue or binary treatments, more so than your knowledge  of C or Java\\nspecifically. Yeah ?\\nStudent : Looking at the end  semester project, I mean, what exactly will you  be testing\\nover there? [Inaud ible]?\\nInstructor (Andrew  Ng) : Of the project?\\nStudent : Yeah.\\nInstructor ( Andrew Ng) : Yeah, let me answer that  later. In a couple of weeks, I shall\\ngive out a handout with guidelines for  the project. But for now, we should think  of the\\ngoal as being to do a  cool piece of machine learning work that will let you  experience the joys of machine learning firsthand and really try to  think about doing a publishable piece\\nof  work.\\nSo many students will try  to build a cool machine learning application. That\\'s  probably\\nthe most common project. Some students  will try to improve state-of-the- art machine\\nlearning. Some of those projects  are also very successful. It\\'s a little bit  harder to do. And\\nthere\\'s also  a smaller minority of students that will sometimes try to  prove — develop the\\ntheory of machine  learning further or try to prove theorems about  machine learning. So\\nthey\\'re usually great  projects of all of those types with applications and machine  learning\\nbeing the most common. Anything else ? Okay, cool.\\nSo that  was it for logistics. Let\\'s talk about learning  algorithms. So can I have the laptop\\ndisplay, please, or the projector? Actually,  could you lower the big screen? Cool. This  is\\namazing customer service. Thank you . I see. Okay, cool. Okay.  No, that\\'s fine. I see.\\nOkay. That\\'s cool. Thanks. Okay .\\nBig screen isn\\'t working today , but I hope you can read things on the  smaller screens out\\nthere. Actually, [ inaudible] I think this room just got  a new projector that — someone\\nsent you  an excited email — was it just on Frid  ay? — saying we just got a new projector\\nand they said 4,000-to -1 something or other brightness ratio. I don \\'t know. Someone was\\nvery excited about  the new projector in this room, but I guess  we\\'ll see that in operation\\non Wednesday .\\nSo start by talking about what  machine learning is. What is machine learning? Actually ,\\ncan you read the text out there ? Raise your hand if the text on the small  screens is legible.\\nOh, okay , cool, mostly legible. Okay. So  I\\'ll just read it out.\\nSo what is machine learning? Way back in about  1959, Arthur Samuel defined machine\\nlearning inform ally as the [inaudible] that gives  computers to learn — [inaudible] that\\ngives computers the ability to learn without  being explicitly programmed. So Arthur\\nSamuel , so way back in the history of machine learning , actually did something very\\ncool, which  was he wrote a checkers program, which would  play games of checkers\\nagainst itself.\\nAnd so because a computer can play  thousands of games against itself relatively quickly,\\nArthur Samuel had his program play thousands of games against  itself, and over time it\\nwould start  to learn to recognize patterns which led to wins and  patterns which led to\\nlosses. So  over time it learned things like that, \"G ee, if I get a lot of pieces taken  by the\\nopponent, then I\\'m  more likely to lose than win,\" or, \" Gee, if I get my pieces into a\\ncertain position, then I\\'m especially likely  to win rather than lose.\"\\nAnd  so over time, Arthur Samuel had a checkers  program that would actually learn to\\nplay check ers by learning what are the sort of board positions  that tend to be associated\\nwith wins and  what are the board positions that tend to be associated  with losses. And\\nway back around 1959 , the amazing thing about this was that his program  actually\\nlearned to play checkers much  better than Arthur Samuel himself could. So even today, there are some people that say , well, computers can\\'t do anything that\\nthey\\'re not explicitly programmed to. And Arthur  Samuel\\'s checkers program was maybe\\nthe  first I think really convincing refutation of this claim . Namely, Arthur Samuel\\nmanaged to  write a checkers program that could play checkers  much better than he\\npersonally could,  and this is an instance of maybe computers learning to  do things that\\nthey were not programmed explicitly  to do.\\nHere\\'s a more  recent, a more modern, more formal definition of  machine learning due to\\nTom Mitchell, who  says that a well-posed learning problem is defined  as follows: He\\nsays that a  computer program is set to learn from an experience E  with respect to some\\ntask T and some  performance measure P if its performance on T as measured  by P\\nimproves with experience E.  Okay. So not only is it a definition,  it even rhymes.\\nSo,  for example, in the case of checkers,  the experience E that a program has would be\\nthe experience of playing lots of games of check ers against itself, say. The task T is  the\\ntask of playing checkers, and  the performance measure P will be something like the\\nfraction of games it wins against a certain  set of human opponents. And by this\\ndefinition, we\\'ll say that Arthur Samuel\\'s check ers program has learned to play checkers,\\nokay?\\nSo as an  overview of what we\\'re going to do in this  class, this class is sort of organized\\ninto four major sections. We\\'re gonna talk about  four major topics in this class, the first\\nof which is supervised learning. So let me  give you an example of that.\\nSo suppose you collect a data set of housing prices . And one of the TAs, Dan Ram age,\\nactually collected a data set for  me last week to use in the example later.  But suppose that\\nyou go to collect statistics  about how much houses cost in a certain geographic area . And\\nDan, the TA, collected  data from housing prices in Portland, Oregon. So  what you can do\\nis let\\'s say  plot the square footage of the house against the list  price of the house, right, so\\nyou collect data on a bunch of houses. And  let\\'s say you get a data set like this  with\\nhouses of different sizes that are listed  for different amounts of money.\\nNow , let\\'s say that I\\'m trying to sell  a house in the same area as Portland, Oregon  as\\nwhere the data comes from. Let \\'s say I have a house that\\'s this size  in square footage, and\\nI want an  algorithm to tell me about how much should I expect  my house to sell for. So\\nthere  are lots of ways to do this, and some  of you may have seen elements of what I\\'m\\nabout to say before.\\nSo one thing you could do is look at this  data and maybe put a straight line to it.  And then\\nif this is my house,  you may then look at the straight line and predict  that my house is\\ngonna go for  about that much money, right? There are other  decisions that we can make,\\nwhich we \\'ll talk about later, which is, well,  what if I don\\'t wanna put a straight line ?\\nMaybe I should put a quadr atic function to it. Maybe that fits the data  a little bit better.\\nYou notice if  you do that, the price of my house goes  up a bit, so that\\'d be nice. And this sort of learning problem of learning to predict  housing prices is an example of\\nwhat\\'s  called a supervised learning problem. And the reason that  it\\'s called supervised\\nlearning is because we \\'re providing the algorithm a data set of a bunch  of square\\nfootages, a bunch of  housing sizes, and as well as sort of the  right answer of what the\\nactual prices of  a number of houses were, right?\\nSo we call this supervised learning because we\\'re  supervising the algorithm or, in other\\nwords, we\\'re giving the algorithm the, quote , right answer for a number of houses. And\\nthen we want the algorithm to learn the  association between the inputs and the outputs\\nand  to sort of give us more of the right answers , okay?\\nIt turns out this  specific example that I drew here is an example of  something called a\\nregression problem. And  the term regression sort of refers to the fact that  the variable\\nyou\\'re trying to predict is  a continuous value and price.\\nThere \\'s another class of supervised learning problems which we\\'ll  talk about, which are\\nclassification problems . And so, in a classification problem, the  variable you\\'re trying to\\npredict is  discreet rather than continuous. So as one specific example  — so actually a\\nstandard data set you  can download online [inaudible] that lots  of machine learning\\npeople have played with.  Let\\'s say you collect a data set on breast  cancer tumors, and you\\nwant to learn  the algorithm to predict whether or not a certain tumor  is malignant.\\nMalignant is the  opposite of benign, right, so malignancy  is a sort of harmful, bad tumor.\\nSo we collect some number of features, some  number of properties of these tumors, and\\nfor the sake of sort of having a simple [ inaudible] explanation, let\\'s just say  that we\\'re\\ngoing to look at the  size of the tumor and depending on the size of  the tumor, we\\'ll try to\\nfigure  out whether or not the tumor is malignant or  benign.\\nSo the tumor is either  malignant or benign, and so the variable in  the Y axis is either zero\\nor 1 , and so your data set may look something like  that, right? And that\\'s 1 and that \\'s\\nzero, okay? And so this  is an example of a classification problem where the variable\\nyou\\'re trying to predict is a discreet  value. It\\'s either zero or 1.\\nAnd in fact, more generally, there  will be many learning problems where we\\'ll have more\\nthan one input variable, more than one  input feature and use more than one variable to try\\nto predict, say, whether a tumor  is malignant or benign. So, for example , continuing with\\nthis, you may instead  have a data set that looks like this. I \\'m gonna part this data set in a\\nslightly different way now. And I\\'m making  this data set look much cleaner than it really\\nis in reality for illustration, okay?\\nFor example, maybe the crosses indicate mal ignant tumors and the \"O\"s may indicate\\nbenign tumors. And so you may  have a data set comprising patients of different ages and\\nwho have different tumor sizes and where a  cross indicates a malignant tumor, and an\\n\"O\" indicates a benign tumor. And  you may want an algorithm to learn to predict,  given a\\nnew patient, whether their tumor  is malignant or benign. So, for example, what a learning algorithm may  do is maybe come in and decide that a\\nstraight line like that separates the two classes of  tumors really well, and so if you have a\\nnew patient who\\'s age and tumor size  fall over there, then the algorithm may predict that\\nthe tumor is benign rather than malignant , okay? So this is just another example of\\nanother supervised learning problem and another classification problem .\\nAnd so it turns out that  one of the issues we\\'ll talk about later in  this class is in this\\nspecific example,  we\\'re going to try to predict whether a tumor  is malignant or benign\\nbased on two  features or based on two inputs, namely the age  of the patient and the tumor\\nsize.  It turns out that when you look at a real  data set, you find that learning algorithms\\noften use other sets of features. In the breast  cancer data example, you also use properties\\nof the tumors, like clump thickness, uniform ity of cell size, uniformity of cell shape ,\\n[inaudible] adhesion  and so on, so various other medical properties.\\nAnd one of the most interesting things  we\\'ll talk about later this quarter is what if  your\\ndata doesn\\'t lie in a two -dimensional or three-dimensional or sort of even  a finite\\ndimensional space, but is it  possible — what if your data actually lies in an  infinite\\ndimensional space? Our plots here are  two-dimensional space. I can\\'t plot you  an infinite\\ndimensional space, right? And  so it turns out that one of the most successful  classes of\\nmachine learning algorithms — some may  call support vector machines — actually takes\\ndata  and maps data to an infinite dimensional space and then  does classification using not\\ntwo features like I \\'ve done here, but an infinite number of features .\\nAnd that will actually be one  of the most fascinating things we talk about when we  go\\ndeeply into classification algorithms. And  it\\'s actually an interesting question, right, so\\nthink about how do you even represent an  infinite dimensional vector in computer\\nmemory? You  don\\'t have an infinite amount of computers. How  do you even represent a\\npoint that lies  in an infinite dimensional space? We\\'ll talk about  that when we get to\\nsupport vector machines , okay?\\nSo let\\'s see . So that was supervised learning. The second of  the four major topics of this\\nclass will  be learning theory. So I have a friend who  teaches math at a different\\nuniversity,  not at Stanford, and when you talk to him  about his work and what he\\'s really\\nout to do, this friend of mine will —  he\\'s a ma th professor, right? —  this friend of mine\\nwill sort of get  the look of wonder in his eyes, and he \\'ll tell you about how in his\\nmat hematical work, he feels like he\\'s discovering  truth and beauty in the universe. And\\nhe says it in sort of a really touching,  sincere way, and then he has this — you  can see it\\nin his eyes — he  has this deep appreciation of the truth and beauty in  the universe as\\nrevealed to him by  the math he does.\\nIn this  class, I\\'m not gonna do any truth and  beauty. In this class, I\\'m gonna talk  about\\nlearning theory to try to convey to  you an understanding of how and why learning\\nalgorithms work so that we can apply these  learning algorithms as effectively as possible.\\nSo, for example, it turns out you can  prove surprisingly deep theorems on when you can\\nguarantee that a learning algorithm will  work, all right? So think about a learning algorithm for reading zip codes. When can you  prove a theorem guaranteeing that a\\nlearning algorithm  will be at least 99.9 percent accurate on  reading zip codes? This is\\nactually somewhat  surprising. We actually prove theorems showing when  you can expect\\nthat to hold.\\nWe\\'ll also sort of delve into learning  theory to try to understand what algorithms can\\napproximate different functions well and also try to  understand things like how much\\ntraining data do  you need? So how many examples of houses do  I need in order for your\\nlearning algorithm  to recognize the pattern between the square footage of a  house and its\\nhousing price? And this  will help us answer questions like if you\\'re trying  to design a\\nlearning algorithm, should you  be spending more time collecting more data or is it  a case\\nthat you already have enough data ; it would be a waste of time to try  to collect more.\\nOkay?\\nSo I think learning algorithms are a very powerful  tool that as I walk around sort of\\nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I\\nfind that there\\'s often a huge difference between  how well someone who really\\nunderstands  this stuff can apply a learning algorithm versus someone who  sort of gets it\\nbut sort of doesn \\'t.\\nThe analogy I like to  think of is imagine you were going to a carp entry school instead of\\na machine learning class , right? If you go to a carpentry  school, they can give you the\\ntools  of carpentry. They\\'ll give you a hammer , a bunch of nails, a screwdriver or\\nwhatever. But a master carpenter will  be able to use those tools far better than most  of us\\nin this room. I know  a carpenter can do things with a hammer and  nail that I couldn\\'t\\npossibly. And  it\\'s actually a little bit like that in machine  learning, too. One thing that\\'s\\nsadly not taught in many courses on machine  learning is how to take the tools of machine\\nlearning and really, really apply them well.\\nSo in the same way, so  the tools of machine learning are I wanna say quite  a bit more\\nadvanced than the tools  of carpentry. Maybe a carpenter will disagree . But a large part of\\nthis class  will be just giving you the raw tools of machine  learning, just the algorithms\\nand so on . But what I plan to do throughout this entire  quarter, not just in the segment of\\nlearning theory, but actually as a theme running through  everything I do this quarter, will\\nbe  to try to convey to you the skills to really  take the learning algorithm ideas and really\\nto  get them to work on a problem.\\nIt\\'s sort of hard for me to stand  here and say how big a deal that is,  but when I walk\\naround companies in Silicon  Valley, it\\'s completely not uncommon for me to  see\\nsomeone using some machine learning algorithm and  then explain to me what they\\'ve\\nbeen  doing for the last six months, and I go , oh, gee, it should have been  obvious from\\nthe start that the last six  months, you\\'ve been wasting your time, right ?\\nAnd so my goal in this  class, running through the entire quarter, not just  on learning\\ntheory, is actually not  only to give you the tools of machine learning,  but to teach you\\nhow to use them  well. And I\\'ve noticed this is something that  really not many other classes teach. And this is something I\\'m really  convinced is a huge deal, and so by the\\nend of this class, I hope all  of you will be master carpenters. I  hope all of you will be\\nreally good  at applying these learning algorithms and getting them to work  amazingly\\nwell in many problems. Okay?\\nLet\\'s see. So [ina udible] the board. After learning theory,  there\\'s another class of learning\\nalgorith ms that I then want to teach you about,  and that\\'s unsupervised learning. So you\\nrecall, right, a little earlier  I drew an example like this, right, where  you have a couple of\\nfeatures, a  couple of input variables and sort of malignant tumors  and benign tumors or\\nwhatever. And that  was an example of a supervised learning problem because the  data\\nyou have gives you the right answer  for each of your patients. The data tells you  this\\npatient has a malignant tumor;  this patient has a benign tumor. So it had  the right\\nanswers, and you  wanted the algorithm to just produce more of the same .\\nIn contrast, in an un supervised learning problem, this is the sort of  data you get, okay?\\nWhere speaking  loosely, you\\'re given a data set, and  I\\'m not gonna tell you what the right\\nanswer is on any of your data. I \\'m just gonna give you a data set and I \\'m gonna say,\\n\"Would you please  find interesting structure in this data set?\" So that \\'s the unsupervised\\nlearning problem where  you\\'re sort of not given the right answer for  everything.\\nSo, for example,  an algorithm may find structure in the data in the  form of the data being\\npartitioned  into two clusters, or clustering is sort of  one example of an unsupervised\\nlearning  problem.\\nSo I hope you can  see this. It turns out that these sort of  unsupervised learning algorithms\\nare also used  in many problems. This is a screen shot —  this is a picture I got from Sue\\nEmvee, who\\'s a PhD student here , who is applying unsupervised learning algorithms to\\ntry to understand gene data, so is  trying to look at genes as individuals and group them\\ninto clusters based on properties of what genes  they respond to — based on properties of\\nhow the genes respond to different experiments.\\nAnother interesting application of [inaudible]  sorts of clustering algorithms is actually\\nimage  processing, this which I got from Steve Gules , who\\'s another PhD student. It turns\\nout what you can do is if you give  this sort of data, say an image, to  certain unsupervised\\nlearning algorithms, they  will then learn to group pixels together and say,  gee, this sort of\\npixel seems  to belong together, and that sort of pixel seems  to belong together.\\nAnd so the  images you see on the bottom — I guess you  can just barely see them on there\\n—  so the images you see on the bottom are group ings — are what the algorithm has done\\nto group certain pixels together. On a small display , it might be easier to just look at the\\nimage on the right. The two images  on the bottom are two sort of identical visualizations\\nof the same grouping of the pixels into  [inaudible] regions.\\nAnd so it turns out that this sort of clust ering algorithm or this sort of unsupervised\\nlearning algorithm, which learns to group pixels together , it turns out to be useful for\\nmany applications in vision, in computer vision image processing . I\\'ll just show you one example, and this  is a rather cool one that two students, Ash utosh\\nSaxena and Min Sun here  did, which is given an image like this,  right? This is actually a\\npicture taken  of the Stanford campus. You can apply that sort  of clustering algorithm and\\ngroup the picture  into regions. Let me actually blow that up so  that you can see it more\\nclearly . Okay. So in the middle, you see  the lines sort of grouping the image together,\\ngrouping the image into [inaudible ] regions.\\nAnd what Ashut osh and Min did was they then applied the learning  algorithm to say can\\nwe take this clust ering and use it to build a 3D model  of the world? And so using the\\nclustering, they then had a learning algorithm  try to learn what the 3D structure of the\\nworld looks like so that they could come  up with a 3D model that you can sort  of fly\\nthrough, okay? Although many  people used to think it\\'s not possible to take  a single\\nimage and build a 3D  model, but using a learning algorithm and that sort  of clustering\\nalgorithm is the first  step. They were able to.\\nI\\'ll just show you one more example. I  like this because it\\'s a picture of Stanford with  our\\nbeautiful Stanford campus. So again , taking the same sort of clustering algorithms,  taking\\nthe same sort of unsupervised  learning algorithm, you can group the pixels into different\\nregions. And using that as a  pre-processing step, they eventually built this sort  of 3D\\nmodel of Stanford campus in  a single picture. You can sort of walk into  the ceiling, look\\naround the campus.  Okay? This actually turned out to be a mix  of supervised and\\nunsupervised learning,  but the unsupervised learning, this sort of  clustering was the first\\nstep.\\nSo it turns out these sorts of un supervised — clustering algorithms are actually routinely\\nused for many different problems, things like organizing  computing clusters, social\\nnetwork analysis, market  segmentation, so if you\\'re a marketer  and you want to divide\\nyour market into  different segments or different groups of people to market to  them\\nseparately; even for astronomical data  analysis and understanding how galaxies are\\nformed.  These are just a sort of small sample of the  applications of unsupervised learning\\nalgorith ms and clustering algorithms that we\\'ll talk about  later in this class.\\nJust one  particularly cool example of an unsupervised learning algorithm  that I want to\\ntell you about.  And to motivate that, I\\'m gonna tell you  about what\\'s called the cocktail\\nparty problem , which is imagine that you\\'re at some cocktail  party and there are lots of\\npeople standing  all over. And you know how it is,  right, if you\\'re at a large party,\\neveryone\\'s talking, it can be sometimes  very hard to hear even the person in front of  you.\\nSo imagine a large cocktail party  with lots of people. So the problem is,  is that all of these\\npeople talking,  can you separate out the voice of just the person  you\\'re interested in\\ntalking to with all  this loud background noise?\\nSo I \\'ll show you a specific example in a second,  but here\\'s a cocktail party that\\'s I guess\\nrather sparsely attended by just two people . But what we\\'re gonna do is we\\'ll  put two\\nmicrophones in the room,  okay? And so because the microphones are just at  slightly\\ndifferent distances to the two people,  and the two people may speak in slightly different\\nvolumes, each microphone will pick up an  overlapping combination of these two people\\'s voices, so slightly different overlapping voices. So  Speaker 1\\'s voice may be more loud\\non Microphone 1, and Speaker 2\\'s voice  may be louder on Microphone 2, whatever.\\nBut the question is, given these  microphone recordings, can you separate out the original\\nspeaker\\'s voices? So I\\'m gonna  play some audio clips that were collected by Tai Yuan\\nLee at UCSD. I\\'m gonna  actually play for you the original raw microphone recordings\\nfrom this cocktail party. So this is the  Microphone 1:\\nMicrophone 1 :\\nOne, two, three,  four, five, six, seven, eight,  nine, ten.\\nMicrophone 2 :\\nUno, dos, t res, cuatro, cinco, se is, siete, ocho, n ueve, diez.\\nInstruct or (Andrew Ng) : So it\\'s a  fascinating cocktail party with people counting from\\none  to ten. This is the second microphone:\\nMicrophone 1:\\nOne , two, three, four, five, six , seven, eight, nine, ten.\\nMicrophone 2:\\nUn o, dos, tres, cuatro,  cinco, seis, siete , ocho, nueve, diez .\\nInstructor (Andrew Ng)  : Okay. So in supervised learning, we don \\'t know what the\\nright answer is,  right? So what we\\'re going to do is  take exactly the two microphone\\nrecordings you  just heard and give it to an unsupervised  learning algorithm and tell the\\nalgorithm which  of these discover structure in the data [inaud ible] or what structure is\\nthere in  this data? And we actually don\\'t know what  the right answer is offhand.\\nSo give this data to an unsupervised learning  algorithm, and what the algorithm does in\\nthis case, it will discover that this data can  actually be explained by two independent\\nspeakers  speaking at the same time, and it can further  separate out the two speakers for\\nyou.  So here\\'s Output 1 of the algorithm:\\nMicrophone 1:\\nOne , two, three, four, five, six , seven, eight, nine, ten.\\nInstructor (Andrew Ng) : And  there\\'s the second algorithm:\\nMicro phone 2: Uno, dos, tres, cuatro , cinco, seis, siet e, ocho, nueve, die z.\\nInstructor (Andrew Ng ): And so the algorithm discovers that, gee , the structure\\nunderlying the data is  really that there are two sources of sound, and  here they are. I\\'ll\\nshow you  one more example. This is a, well,  this is a second sort of different pair of\\nmicrophone recordings:\\nMicrophone  1:\\nOne, two, three , four, five, six, seven, eight , nine, ten.\\nMicrophone  2:\\n[Music playing.]\\nInstructor (Andrew Ng): So the  poor guy is not at a cocktail party. He \\'s talking to his\\nradio. There\\'s  the second recording:\\nMicrophone 1 :\\nOne, two, three,  four, five, six, seven, eight,  nine, ten.\\nMicrophone 2 :\\n[Music playing.]\\nInstructor (Andrew Ng) : Right.  And we get this data. It\\'s the same  unsupervised\\nlearning algorithm. The algorithm  is actually called independent component analysis, and\\nlater in this quarter, you\\'ll see why.  And then output\\'s the following:\\nMicrophone 1:\\nOne, two , three, four, five, six, seven , eight, nine, ten.\\nInstructor (Andrew Ng): And that\\'s the  second one:\\nMicrophone 2:\\n[Music playing.]\\nInstructor (Andrew Ng): Okay. So it  turns out that beyond solving the cocktail party\\nalgorithm, this specific class of unsupervised  learning algorithms are also applied to a\\nb unch of other problems, like in text processing or  understanding functional grading and\\nmachine data, like  the magneto-encephalogram would be  an EEG data. We\\'ll talk about\\nthat more when we go and describe ICA or  independent component analysis algorithms,\\nwhich is what  you just saw. And as an aside, this algorithm I just showed  you, it seems like it must be a pretty\\ncomplicated algorithm, right, to take  this overlapping audio streams and separate them\\nout . It sounds like a pretty complicated thing to do . So you\\'re gonna ask how complicated\\nis it really to implement an algorithm like this?  It turns out if you do it in MATLAB , you\\ncan do it in one line  of code.\\nSo I got this  from Samuel Wyse at Toronto, U of Toronto , and the example I showed you\\nactually  used a more complicated ICA algorithm than this.  But nonetheless, I guess this is\\nwhy  for this class I\\'m going to ask you to  do most of your programming in MATLAB and\\nOctave because if you try to implement the  same algorithm in C or Java or something, I\\ncan tell you from personal, painful experience , you end up writing pages and pages of\\ncode rather than relatively few lines of code.  I\\'ll also mention that it did take researchers\\nmany, many years to come up with that  one line of code, so this is not easy .\\nSo that was unsupervised  learning, and then the last of the four major  topics I wanna tell\\nyou about is reinforcement  learning. And this refers to problems where you don \\'t do one-\\nshot decision-making.  So, for example, in the supervised learning cancer  prediction\\nproblem, you have a patient come  in, you predict that the cancer is malignant  or benign.\\nAnd then based on your  prediction, maybe the patient lives or dies, and  then that\\'s it,\\nright? So  you make a decision and then there\\'s a consequence . You either got it right or\\nwrong . In reinforcement learning problems, you are usually asked  to make a sequence of\\ndecisions over  time.\\nSo, for example,  this is something that my students and I work on . If I give you the keys\\nto  an autonomous helicopter — we actually ha ve this helicopter  here at Stanford, — how\\ndo you  write a program to make it fly, right?  You notice that if you make a wrong\\ndecision on a helicopter, the consequence of crashing  it may not happen until much later.\\nAnd in fact, usually you need to make a  whole sequence of bad decisions to crash a\\nhelicopter. But conversely, you also  need to make a whole sequence of good decisions in\\norder to fly a helicopter really well.\\nSo I\\'m gonna show you some  fun videos of learning algorithms flying helicopters. This is\\na video of our helicopter at Stanford flying  using a controller that was learned using a\\nreinforcement learning algorithm. So this was done  on the Stanford football field, and\\nwe \\'ll zoom out the camera in a second. You \\'ll sort of see the trees planted in the sky . So\\nmaybe this is one of the  most difficult aerobatic maneuvers flown on any helicopter  under\\ncomputer control. And this controller,  which is very, very hard for a human to  sit down\\nand write out, was learned  using one of these reinforcement learning algorithms.\\nJust a word about that: The basic idea  behind a reinforcement learning algorithm is this\\nide a of what\\'s called a reward function. What  we have to think about is imagine you\\'re\\ntrying to train a dog. So every  time your dog does something good, you say,  \"Good dog,\"\\nand you reward the  dog. Every time your dog does something bad,  you go, \"Bad dog,\"\\nright ? And hopefully, over time, your dog will  learn to do the right things to get more of\\nthe positive rewards, to get more of  the \"Good dogs\" and to get fewer of  the \"Bad dogs.” So the way we teach a helicopter to fly or  any of these robots is sort of the same thing .\\nEvery time the helicopter crashes, we  go, \"Bad helicopter,\" and every time it  does the\\nright thing, we go,  \"Good helicopter,\" and over time it learns how  to control itself so as to\\nget more  of these positive rewards.\\nSo reinforcement  learning is — I think of it as a way  for you to specify what you want\\ndone , so you have to specify what is a \" good dog\" and what is a \"bad dog \" behavior. And\\nthen it\\'s up  to the learning algorithm to figure out how to maximize  the \"good dog\"\\nreward signals  and minimize the \"bad dog\" punishments.\\nSo it turns out reinforcement learning is applied  to other problems in robotics. It\\'s applied\\nto things in web crawling and so on.  But it\\'s just cool to show videos, so  let me just show\\na bunch of them . This learning algorithm was actually implemented by our head  TA,\\nZico, of programming a  four-legged dog. I guess Sam Shriver  in this class also worked\\non the project  and Peter Renfrew and Mike and a few  others. But I guess this really is a\\ngood dog/bad dog since it\\'s a  robot dog.\\nThe second video on  the right, some of the students, I guess  Peter, Zico, Tonca working\\non a robotic snake, again using learning algorithms to  teach a snake robot to climb over\\nob stacles.\\nBelow that, this  is kind of a fun example. Ashutosh  Saxena and Jeff Michaels used\\nlearning algorithms  to teach a car how to drive at reasonably high  speeds off roads\\navoiding obstacles.\\nAnd on the lower right, that\\'s  a robot programmed by PhD student Eva Roshen to  teach a\\nsort of somewhat strangely configured robot  how to get on top of an obstacle, how  to get\\nover an obstacle. Sorry.  I know the video\\'s kind of small. I  hope you can sort of see it.\\nOkay?\\nSo I think all of  these are robots that I think are very difficult to  hand-code a controller\\nfor by learning  these sorts of learning algorithms. You can in relatively  short order get a\\nrobot to do  often pretty amazing things.\\nOkay.  So that was most of what I wanted to say  today. Just a couple more last things, but\\nlet me just check what questions you have  right now. So if there are no questions,  I\\'ll just\\nclose with two reminders,  which are after class today or as you start to  talk with other\\npeople in this class,  I just encourage you again to start to form project  partners, to try to\\nfind project partners  to do your project with. And also, this  is a good time to start forming\\nstudy  groups, so either talk to your friends or post  in the newsgroup, but we just\\nencourage you to try to start to do both  of those today, okay? Form study groups,  and try\\nto find two other project partners .\\nSo thank you. I\\'m  looking forward to teaching this class, and I\\'ll  see you in a couple of\\ndays. [End of Audio]\\nDuration:  69 minutes')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6040d6-2f96-4751-95ce-a13315b5ce5d",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cebd2974-8dad-4948-a7a0-ab08e7f8efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/77hjsc2j58s68phj_xx_yps80000gn/T/ipykernel_33422/1742550774.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m embedding = OpenAIEmbeddings()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:226\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    225\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28mself\u001b[39m.__pydantic_validator__.validate_python(data, self_instance=\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2f708-c41a-4d72-960a-e200b8b8f670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ce3a-b794-483a-9802-f296adcc517d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
